{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7e4330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esauhutcherson/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import faiss\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac91b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")  # Add your Hugging Face token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80bd3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [15:11<00:00, 455.86s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:34<00:00, 17.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralModel(\n",
       "  (embed_tokens): Embedding(32000, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x MistralDecoderLayer(\n",
       "      (self_attn): MistralAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): MistralMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  (rotary_emb): MistralRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DistilBERT model and tokenizer\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model = AutoModel.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e05253",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d56219",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ab72a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>formatted_experience_level</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>work_type</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>job_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Essentia Health</td>\n",
       "      <td>Long Term Care Administrator</td>\n",
       "      <td>Looking to Make a Difference in Someone’s Life...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Virginia, MN</td>\n",
       "      <td>Director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>55792.0</td>\n",
       "      <td>Long Term Care Administrator Looking to Make a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STIIIZY</td>\n",
       "      <td>Retail Procurement Assistant</td>\n",
       "      <td>We are seeking a proactive and detail-oriented...</td>\n",
       "      <td>58240.0</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>Retail Procurement Assistant We are seeking a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Net2Source Inc.</td>\n",
       "      <td>Quality Control Inspector</td>\n",
       "      <td>Title: Product Quality Inspector Location: Alp...</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONTRACT</td>\n",
       "      <td>30004.0</td>\n",
       "      <td>Quality Control Inspector Title: Product Quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swoon</td>\n",
       "      <td>Creative Project Manager - 79439</td>\n",
       "      <td>Our client is a Fortune 100 company &amp; leading ...</td>\n",
       "      <td>70720.0</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONTRACT</td>\n",
       "      <td>60601.0</td>\n",
       "      <td>Creative Project Manager - 79439 Our client is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Murphy USA</td>\n",
       "      <td>CASHIER (full-time &amp; part-time opportunities)</td>\n",
       "      <td>Job Posting\\n\\nAs one of the largest national ...</td>\n",
       "      <td>28080.0</td>\n",
       "      <td>Lapeer, MI</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PART_TIME</td>\n",
       "      <td>48446.0</td>\n",
       "      <td>CASHIER (full-time &amp; part-time opportunities) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_name                                          title  \\\n",
       "0  Essentia Health                   Long Term Care Administrator   \n",
       "1          STIIIZY                   Retail Procurement Assistant   \n",
       "2  Net2Source Inc.                      Quality Control Inspector   \n",
       "3            Swoon               Creative Project Manager - 79439   \n",
       "4       Murphy USA  CASHIER (full-time & part-time opportunities)   \n",
       "\n",
       "                                         description    salary  \\\n",
       "0  Looking to Make a Difference in Someone’s Life...  110000.0   \n",
       "1  We are seeking a proactive and detail-oriented...   58240.0   \n",
       "2  Title: Product Quality Inspector Location: Alp...  104000.0   \n",
       "3  Our client is a Fortune 100 company & leading ...   70720.0   \n",
       "4  Job Posting\\n\\nAs one of the largest national ...   28080.0   \n",
       "\n",
       "          location formatted_experience_level skills_desc  work_type  \\\n",
       "0     Virginia, MN                   Director         NaN  FULL_TIME   \n",
       "1  Los Angeles, CA                  Associate         NaN  FULL_TIME   \n",
       "2   Alpharetta, GA                  Associate         NaN   CONTRACT   \n",
       "3      Chicago, IL                  Associate         NaN   CONTRACT   \n",
       "4       Lapeer, MI                Entry level         NaN  PART_TIME   \n",
       "\n",
       "   zip_code                                       job_matching  \n",
       "0   55792.0  Long Term Care Administrator Looking to Make a...  \n",
       "1   90001.0  Retail Procurement Assistant We are seeking a ...  \n",
       "2   30004.0  Quality Control Inspector Title: Product Quali...  \n",
       "3   60601.0  Creative Project Manager - 79439 Our client is...  \n",
       "4   48446.0  CASHIER (full-time & part-time opportunities) ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/job_postings_cleaned.csv')  # Load your dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68846ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "formatted_experience_level\n",
       "Mid-Senior level    4625\n",
       "Entry level         3263\n",
       "Associate           1382\n",
       "Director             447\n",
       "Internship           144\n",
       "Executive            139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['formatted_experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a028313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze(0).numpy()\n",
    "\n",
    "def get_mistral_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the last hidden state (sequence_length x hidden_dim)\n",
    "    hidden_states = outputs.last_hidden_state  # shape: (1, seq_len, hidden_dim)\n",
    "\n",
    "    # Option 1: Use the mean pooling of all token embeddings (common for decoder LMs)\n",
    "    embedding = hidden_states.mean(dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b6f9dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [02:19<388:19:07, 139.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m job_embeddings = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m job_text \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[33m'\u001b[39m\u001b[33mjob_matching\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     emb = \u001b[43mget_mistral_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjob_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ensure it's a string\u001b[39;00m\n\u001b[32m      4\u001b[39m     job_embeddings.append(emb)\n\u001b[32m      6\u001b[39m job_embeddings = np.vstack(job_embeddings)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mget_mistral_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      8\u001b[39m inputs = tokenizer(text, return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, max_length=\u001b[32m512\u001b[39m).to(device)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Get the last hidden state (sequence_length x hidden_dim)\u001b[39;00m\n\u001b[32m     14\u001b[39m hidden_states = outputs.last_hidden_state  \u001b[38;5;66;03m# shape: (1, seq_len, hidden_dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/transformers/models/mistral/modeling_mistral.py:536\u001b[39m, in \u001b[36mMistralModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    524\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    525\u001b[39m         partial(decoder_layer.\u001b[34m__call__\u001b[39m, **flash_attn_kwargs),\n\u001b[32m    526\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    533\u001b[39m         position_embeddings,\n\u001b[32m    534\u001b[39m     )\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    548\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/transformers/models/mistral/modeling_mistral.py:265\u001b[39m, in \u001b[36mMistralDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m residual = hidden_states\n\u001b[32m    264\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    268\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/transformers/models/mistral/modeling_mistral.py:59\u001b[39m, in \u001b[36mMistralMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ResumeMatcher-BwIgqEkW/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "job_embeddings = []\n",
    "for job_text in tqdm(df['job_matching']):\n",
    "    emb = get_mistral_embedding(str(job_text))  # ensure it's a string\n",
    "    job_embeddings.append(emb)\n",
    "\n",
    "job_embeddings = np.vstack(job_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b47333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure your job_embeddings is a float32 numpy array\n",
    "job_embeddings_np = np.array(job_embeddings).astype('float32')\n",
    "\n",
    "np.save('saved_data/MiniLML6/job_embeddings.npy', job_embeddings_np)\n",
    "\n",
    "# Create a FAISS index (use cosine similarity via inner product + normalization)\n",
    "faiss.normalize_L2(job_embeddings_np)\n",
    "index = faiss.IndexFlatIP(job_embeddings_np.shape[1])\n",
    "index.add(job_embeddings_np)\n",
    "\n",
    "# Save DataFrame along with FAISS index (so index[i] corresponds to df.iloc[i])\n",
    "df.reset_index(drop=True, inplace=True)  # important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b45e1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, \"saved_data/MiniLML6/job_faiss.index\")\n",
    "\n",
    "# Save dataframe\n",
    "df.to_pickle(\"saved_data/MiniLML6/job_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529ffd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"saved_data/MiniLML6/job_faiss.index\")\n",
    "df = pd.read_pickle(\"saved_data/MiniLML6/job_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a137df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_jobs(resume_text, df_jobs, job_embeddings, top_k=10):\n",
    "    # 2. Get corresponding filtered embeddings\n",
    "    filtered_embeddings = []\n",
    "    for idx in df_jobs.index:\n",
    "        filtered_embeddings.append(job_embeddings[idx])  # assuming job_embeddings[i] matches df_jobs.iloc[i]\n",
    "\n",
    "    filtered_embeddings = np.vstack(filtered_embeddings).astype(\"float32\")\n",
    "\n",
    "    # 3. Get resume embedding\n",
    "    resume_embedding = get_embedding(resume_text).astype('float32').reshape(1, -1)\n",
    "    faiss.normalize_L2(resume_embedding)  # Normalize the resume embedding\n",
    "\n",
    "    # 4. Set up FAISS index with filtered embeddings\n",
    "    index = faiss.IndexFlatIP(resume_embedding.shape[1])  # Using Inner Product (cosine similarity if normalized)\n",
    "    faiss.normalize_L2(filtered_embeddings)  # Normalize the job embeddings\n",
    "    index.add(filtered_embeddings)\n",
    "\n",
    "    # 5. Search the index for top_k similar jobs\n",
    "    distances, indices = index.search(resume_embedding, top_k)\n",
    "\n",
    "    # 6. Fetch top results from the DataFrame\n",
    "    results_df = df_jobs.iloc[indices[0]].copy()  # Fetch the rows of the top k matches\n",
    "    results_df['similarity'] = distances[0]  # Add similarity score to the DataFrame\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b36eb61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 17.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# for resume text in data/resume_queries.csv['resume_text'] embed each text and find top 10 job matches\n",
    "resume_df = pd.read_csv('data/resume_queries.csv')\n",
    "\n",
    "resume_texts = resume_df['Resume_str'].tolist()\n",
    "\n",
    "# for each resume text, get the top 10 job matches\n",
    "results = {}\n",
    "for resume_text in tqdm(resume_texts):\n",
    "    # Filter jobs based on experience level\n",
    "    top_matches = match_jobs(resume_text, df, job_embeddings, top_k=10)\n",
    "    results[resume_text] = top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6d077ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_rows = []\n",
    "\n",
    "for resume_text, top_matches_df in results.items():\n",
    "    # Add the resume text as a new column, repeated for each row\n",
    "    temp_df = top_matches_df.copy()\n",
    "    temp_df.insert(0, 'resume_text', resume_text)\n",
    "    flattened_rows.append(temp_df)\n",
    "\n",
    "# Concatenate all into one DataFrame\n",
    "final_df = pd.concat(flattened_rows, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('MiniLM_Cosine.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResumeMatcher-BwIgqEkW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
