
# üìÑ Resume Recommendation Tool (FastAPI + Ollama + Embeddings)

This project is a resume-to-job matching system built with **FastAPI**, **Ollama (LLM)**, **SBERT embeddings**, and a local **SQLite** database of job listings. It allows users to upload a PDF resume and returns the top job matches, complete with a match score, matched skills, and match reason.

---

## üöÄ Features

- ‚úÖ PDF resume parsing with `PyMuPDF`
- ‚úÖ Skill extraction using Ollama (LLaMA/Mistral)
- ‚úÖ Job embeddings with SentenceTransformers (SBERT)
- ‚úÖ Hybrid ranking with embeddings + LLaMA for match reason
- ‚úÖ Word cloud generation
- ‚úÖ Full CRUD for jobs via FastAPI
- ‚úÖ Docker-ready for deployment

---

## üß± Project Structure

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # FastAPI routes
‚îÇ   ‚îú‚îÄ‚îÄ db/                  # SQLAlchemy database setup
‚îÇ   ‚îú‚îÄ‚îÄ models/              # ORM models
‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ scripts/             # Data loaders and utilities
‚îÇ   ‚îî‚îÄ‚îÄ services/            # Business logic (matcher, parser, etc.)
‚îú‚îÄ‚îÄ alembic/                 # Database migrations
‚îú‚îÄ‚îÄ app.db                   # SQLite database (not included in Docker image)
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
```

---

## üß™ Local Development

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/resume-recommendation-tool.git
cd resume-recommendation-tool/backend
```

### 2. Set Up Environment

Use `venv` or `conda`. Example with `venv`:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

### 3. Run the API with Uvicorn

```bash
uvicorn app.main:app --reload
```

> The API will be available at http://127.0.0.1:8000

You can now upload resumes via `/docs` or use Postman/your frontend.

> ‚ö†Ô∏è Make sure **Ollama** is running locally (`ollama serve`)

---

## üê≥ Docker Deployment

### 1. Build Docker Image

```bash
docker build -t resume-api .
```

### 2. Run with SQLite DB Mounted

```bash
docker run -it --rm   -v /path/to/resumeapp.db:/app/app.db   -p 8000:8000   resume-api
```

Or if using **local Ollama**, use host networking:

```bash
docker run -it --rm   --network host   -v /path/to/resumeapp.db:/app/app.db   -p 8000:8000   resume-api
```

### 3. Enable Auto-Restart on Reboots

```bash
docker run -d   --restart unless-stopped   --network host   -v /home/ubuntu/resumeapp.db:/app/app.db   -p 8000:8000   resume-api
```

---

## üîó API Endpoint

### `POST /resume/match`

**Request:**
- Content-Type: `multipart/form-data`
- Field: `file` ‚Üí your `.pdf` resume

**Response:**

```json
{
  "resume_skills": [...],
  "matches": [
    {
      "jobId": 123,
      "matchScore": 0.78,
      "matchedSkills": [...],
      "matchReason": "Mentions Java and CI/CD, which align with this job."
    }
  ],
  "wordCloud": [
    { "text": "python", "value": 5 },
    ...
  ]
}
```

---

## üß† Matching Logic

1. Extracts text from PDF using `PyMuPDF`
2. Skills are extracted using a local LLM via Ollama
3. Skills are embedded using SBERT (MiniLM)
4. Compared to job embeddings using cosine similarity
5. Top jobs are re-ranked with Mistral and a match reason is generated

---

## ‚ö†Ô∏è Notes

- The database (`app.db`) is **not included in the Docker image**
- Make sure **Ollama** is installed and running (`ollama serve`)
- Word clouds use extracted skills and frequency from the full resume

---

## üìö License

MIT License
